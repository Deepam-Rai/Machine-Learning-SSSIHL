{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Review Questions-I from MDSC-301(P)**\n",
    "**Assignment - II**\n",
    "------------------------------------------------\n",
    "**Author: Deepam Rai, 21231, II MSc**\n",
    "\n",
    "Date: September 5, 2022\n",
    "\n",
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1. Which Linear Regression training algorithm can you use if you have\n",
    "a training set with millions of features?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Gradient Descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q2. Suppose the features in your training set have very different scales.\n",
    "Which algorithms might suffer from this, and how? What can you\n",
    "do about it?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm that suffers: Gradient Descent.  \n",
    "Solution: We have to scale the features, commonly we do standardadization or normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q3.  Suppose you use Batch Gradient Descent and you plot the validation\n",
    "error at every epoch. If you notice that the validation error\n",
    "consistently goes up, what is likely going on? How can you fix this?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model might be overfitting on the train data.  \n",
    "We can fix this using Regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q4. Is it a good idea to stop Mini-batch Gradient Descent immediately\n",
    "when the validation error goes up?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: No, because the validation error might have gone up for just that specific validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q5. Suppose you are using Polynomial Regression. You plot the learning\n",
    "curves and you notice that there is a large gap between the training\n",
    "error and the validation error. What is happening? What are three\n",
    "ways to solve this?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might be using very high degree Polynomial regression model which consequently is highly overfitting the train data.  \n",
    "Solution:\n",
    "1. Regularization.\n",
    "2. Using lower degree polynomial.\n",
    "3. Cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q6. Suppose you are using Ridge Regression and you notice that the\n",
    "training error and the validation error are almost equal and fairly\n",
    "high. Would you say that the model suffers from high bias or high\n",
    "variance? Should you increase the regularization hyperparameter $\\alpha$\n",
    "or reduce it?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is suffering from low-bias and high-variance.  \n",
    "We should increase the regularization hyperparameter $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q7. Why would you want to use:**\n",
    "   - Ridge Regression instead of plain Linear Regression (i.e., without any regularization)?\n",
    "       - Ans: To\n",
    "           1. Prevent model from overfitting the train data.\n",
    "           1. Keep the weights as small as possible.\n",
    "   - Lasso instead of Ridge Regression?\n",
    "       - Ans: Because\n",
    "           1. Lasso tends to make the coefficients of least important features zero, unlike ridge.\n",
    "           1. Thus Lasso regression automatically selects the important features.\n",
    "   - Elastic Net instead of Lasso?\n",
    "       - Ans: Because Lasso performs poorly when \n",
    "           1. Number of observations are less than the number of features.\n",
    "           1. Or the features are strongly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q8.  Can you name four of the main challenges in Machine Learning?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Lack of quality Data.\n",
    "1. Overfitting on training data.\n",
    "1. Underfitting of training data.\n",
    "1. Non-representative training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q9. If your model performs great on the training data but generalizes\n",
    "poorly to new instances, what is happening? Can you name three\n",
    "possible solutions?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has overfit on the training data and has high bias and high variance.  \n",
    "Solutions:  \n",
    "1. Cross validation.\n",
    "1. Regularization.\n",
    "1. Adding more quality data to the train dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q10. What is a test set, and why would you want to use it?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set is the subset of the total dataset that is kept unseen from the model during training phase.  \n",
    "It is used to test the performance of the model and measure the generalization done by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q11.  What is the purpose of a validation set?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation set is used to get the real time performance of the model during the training phase.  \n",
    "It helps us to prevent the overfitting of the model on the train data by early stopping of the algorithm in case overfitting is detected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q12. What are different loss functions? Exaplain their importance?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different loss functions are:\n",
    "1. MSE(Mean Square Error)\n",
    "    - It penalizes larger error more than smaller error, because of square of the error taken.\n",
    "    - It is differentiable.\n",
    "    - It is less robust to outliers.\n",
    "1. MAE(Mean Absolute Error)\n",
    "    - It is robust to outliers.\n",
    "1. Hinge Loss\n",
    "    - It is used for classification techniques.\n",
    "    - It is non-differentiable.\n",
    "1. Cross Entropy Loss\n",
    "    - It is used for classification techniques.\n",
    "    - It penalizes the the confident but wrong predictions more than others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q13. Explain the following:**\n",
    "- Gradient descent\n",
    "    - Definition: It is an iterative optimization technique to find the local minima of a function by picking up an arbitrary point.\n",
    "- Batch gradient,\n",
    "    - Definition: It is a variant of gradient descent where we use the whole training dataset for an iteration at once.\n",
    "    - It is computationally expensive.\n",
    "- Mini-batch gradient descent\n",
    "    - Definition: It is a variant of gradient descent where we take subset or batches of the training dataset for each iteration in the epoch.\n",
    "    - It lies inbetween batch gradient descent and stochastic gradient descent.\n",
    "    - This is the often used method in practicality.\n",
    "- Stochastic Gradient Descent\n",
    "    - Definition: It is a variant of gradient descent where we take just one train datapoint for each iteration in the epoch.\n",
    "    - It requires less computation for each iteration, but the time taken to finish an epoch is very large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q14. What is learning rate?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition: Learning rate can be defined as hyperparameter that measures the changes in the model done by the learning algorithm for each step in response to the loss gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q15. Define the following terms. Explain their importance in the data analysis.**\n",
    "- $R^2$\n",
    "- Adjusted $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **R<sup>2</sup>**\n",
    "**Definition:** It is a metric to measure the performance of machine learning models which is calculated as:  \n",
    "$R^2= 1- \\frac{SS_{Residuals}}{SS_{Total}}$  \n",
    "    - It indicates to us how much proportion of the total variance is explained by a feature.\n",
    "    - It assumes that all independent features taken into consideration explains some part of the total variance.\n",
    "2. **Adjusted R<sup>2</sup>**\n",
    "**Definition:** It is the improved version of R<sup>2</sup> and is calculated as:  \n",
    "$R^2_{Adjusted} = 1 - \\frac{(1-R^2)(n-1)}{n-p-1}$\n",
    "where $R^2$ is R-squared, $n$ is number of observations and $p$ is the number of features.  \n",
    "    - It is a better metric than R<sup>2</sup>\n",
    "    - It considers only those independent features which actually have affect on the total variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q16. Explain One-Hot Encoding and Label Encoding.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. One Hot Encoding  \n",
    "It is a technique to deal with categorical variables. In a categorical feature, for each unique category it creates a new column and fill it with 1 if value in original feature is the same category else 0.\n",
    "2. Label Encoding  \n",
    "It is a technique to deal with categorical variables where the unique categories are mapped to unique integer values so as to make them machine readable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q17. What are the assumption on Naive Bayes algorithm in classification?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q18. What is the difference between classification and regression?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q19. How to ensure that the model is not overfitting?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q20. List the main advantage of Naive Bayes?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q21. What you shoud do when your model is suffereing from:**\n",
    "- Low bias and high variance?\n",
    "- High bias and low variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q22. What is the 'Naive' in the Naive Bayes Classifier?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q23. What is bias-variance tradeoff in Machine Learning ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q24. Explain different trade-offs in Machine Learning algorithms?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Q25. What is cross-validation and how it is useful in traing ML models?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
